version: "3.8"
services:
  llama3_finetuning:
    image: your_image_name:latest  # Replace with the correct Docker image
    command: >
      tune run --nproc_per_node 4 full_finetune_distributed --config llama3_1/8B_full
    environment:
      - OUTPUT_DIR=${OUTPUT_DIR:-/tmp/torchtune/llama3_1_8B/full}
      - TOKENIZER_PATH=${TOKENIZER_PATH:-/tmp/Meta-Llama-3.1-8B-Instruct/original/tokenizer.model}
      - DATASET_PATH=${DATASET_PATH:-/tmp/Meta-Llama-3.1-8B-Instruct/original/alpaca}
    volumes:
      - ${OUTPUT_DIR}:${OUTPUT_DIR}
      - ${TOKENIZER_PATH}:${TOKENIZER_PATH}
      - ${DATASET_PATH}:${DATASET_PATH}
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 64Gi  # Adjust memory as needed
    runtime: nvidia  # This ensures the job runs 
    networks:
      - llama-network

networks:
  llama-network:
    driver: bridge

